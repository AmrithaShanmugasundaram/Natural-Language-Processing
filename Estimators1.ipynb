{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ff8bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test sentence: + I am Sam green -\n",
      "Probability of the text using Maximum Likelihood Estimation (MLE): 0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams, word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "with open(\"corpus.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = preprocess(text)\n",
    "words = word_tokenize(text)\n",
    "bigrams = list(ngrams(words, 2))\n",
    "unique = list(set(words))\n",
    "df = pd.DataFrame(0, columns=unique, index=unique)\n",
    "for w1, w2 in bigrams:\n",
    "    df.at[w1, w2] += 1\n",
    "\n",
    "prob = {}\n",
    "for word1 in df.index:\n",
    "    total_count = df.loc[word1].sum()\n",
    "    if total_count == 0:\n",
    "        prob[word1] = {word2: 0.0 for word2 in df.columns}\n",
    "    else:\n",
    "        prob[word1] = {word2: count / total_count for word2, count in df.loc[word1].items() if total_count != 0}\n",
    "\n",
    "test_snt = input('Enter test sentence: ')\n",
    "test_snt=preprocess(test_snt)\n",
    "words3 = word_tokenize(test_snt)\n",
    "\n",
    "bigr = list(ngrams(words3, 2))\n",
    "\n",
    "prob_MLE = 1.0\n",
    "for word1, word2 in bigr:\n",
    "    if word1 in prob and word2 in prob[word1]:\n",
    "        prob_MLE *= prob[word1][word2]\n",
    "print(\"Probability of the text using Maximum Likelihood Estimation (MLE):\", prob_MLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55b39887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eggs</th>\n",
       "      <th>not</th>\n",
       "      <th>i</th>\n",
       "      <th>do</th>\n",
       "      <th>like</th>\n",
       "      <th>am</th>\n",
       "      <th>sam</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sam</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eggs  not  i  do  like  am  sam  green\n",
       "eggs      0    0  0   0     0   0    0      0\n",
       "not       0    0  0   0     1   0    0      0\n",
       "i         0    0  0   1     0   2    0      0\n",
       "do        0    1  0   0     0   0    0      0\n",
       "like      0    0  0   0     0   0    0      1\n",
       "am        0    0  1   0     0   0    1      0\n",
       "sam       0    0  1   0     0   0    1      0\n",
       "green     1    0  0   0     0   0    0      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca7ca4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test sentence: + I am Sam green -\n",
      "Probability of the text using Laplace smoothing: 0.005454545454545455\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams, word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "with open(\"corpus.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = preprocess(text)\n",
    "words = word_tokenize(text)\n",
    "bigrams = list(ngrams(words, 2))\n",
    "unique = list(set(words))\n",
    "df = pd.DataFrame(0, columns=unique, index=unique)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    df.at[w1, w2] += 1\n",
    "\n",
    "v = len(unique)\n",
    "\n",
    "prob = {}\n",
    "for word1 in df.index:\n",
    "    total_count = df.loc[word1].sum()\n",
    "    prob[word1] = {}\n",
    "    for word2, count in df.loc[word1].items():\n",
    "        prob[word1][word2] = (count + 1) / (total_count + v)\n",
    "\n",
    "test_snt = input('Enter test sentence: ')\n",
    "test_snt = preprocess(test_snt)\n",
    "words3 = word_tokenize(test_snt)\n",
    "bigr = list(ngrams(words3, 2))\n",
    "\n",
    "prob_Laplace = 1.0\n",
    "for word1, word2 in bigr:\n",
    "    if word1 in prob and word2 in prob[word1]:\n",
    "        prob_Laplace *= prob[word1][word2]\n",
    "\n",
    "print(\"Probability of the text using Laplace smoothing:\", prob_Laplace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e72cfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test sentence: + I am Sam green -\n",
      "Probability of the text using Lidstone's smoothing: 0.00744047619047619\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams, word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "with open(\"corpus.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = preprocess(text)\n",
    "words = word_tokenize(text)\n",
    "bigrams = list(ngrams(words, 2))\n",
    "unique = list(set(words))\n",
    "df = pd.DataFrame(0, columns=unique, index=unique)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    df.at[w1, w2] += 1\n",
    "\n",
    "v = len(unique)\n",
    "delta = 0.5  \n",
    "\n",
    "prob = {}\n",
    "for word1 in df.index:\n",
    "    total_count = df.loc[word1].sum()\n",
    "    prob[word1] = {}\n",
    "    for word2, count in df.loc[word1].items():\n",
    "        prob[word1][word2] = (count + delta) / (total_count + delta * v)\n",
    "\n",
    "test_snt = input('Enter test sentence: ')\n",
    "test_snt = preprocess(test_snt)\n",
    "words3 = word_tokenize(test_snt)\n",
    "bigr = list(ngrams(words3, 2))\n",
    "\n",
    "prob_Lidstone = 1.0\n",
    "for word1, word2 in bigr:\n",
    "    if word1 in prob and word2 in prob[word1]:\n",
    "        prob_Lidstone *= prob[word1][word2]\n",
    "\n",
    "print(\"Probability of the text using Lidstone's smoothing:\", prob_Lidstone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14cd0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter test sentence: + I am Sam green -\n",
      "Probability of the text using Jeffrey smoothing: 0.00744047619047619\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams, word_tokenize\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "with open(\"corpus.txt\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "text = preprocess(text)\n",
    "words = word_tokenize(text)\n",
    "bigrams = list(ngrams(words, 2))\n",
    "unique = list(set(words))\n",
    "df = pd.DataFrame(0, columns=unique, index=unique)\n",
    "\n",
    "for w1, w2 in bigrams:\n",
    "    df.at[w1, w2] += 1\n",
    "\n",
    "v = len(unique)\n",
    "delta = 0.5 \n",
    "\n",
    "prob = {}\n",
    "for word1 in df.index:\n",
    "    total_count = df.loc[word1].sum()\n",
    "    prob[word1] = {}\n",
    "    mu = total_count / (total_count + (v * delta)) if total_count != 0 else 0 \n",
    "    for word2, count in df.loc[word1].items():\n",
    "        prob[word1][word2] = (mu * count / total_count) + ((1 - mu) / v) if total_count != 0 else 1 / v\n",
    "\n",
    "test_snt = input('Enter test sentence: ')\n",
    "test_snt = preprocess(test_snt)\n",
    "words3 = word_tokenize(test_snt)\n",
    "bigr = list(ngrams(words3, 2))\n",
    "\n",
    "prob_Jeffrey = 1.0\n",
    "for word1, word2 in bigr:\n",
    "    if word1 in prob and word2 in prob[word1]:\n",
    "        prob_Jeffrey *= prob[word1][word2]\n",
    "\n",
    "print(\"Probability of the text using Jeffrey smoothing:\", prob_Jeffrey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1330a69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for held-out data:\n",
      "('sastra', 'university') 0.3333333333333333\n",
      "('university', 'located') 0\n",
      "('located', 'thanjavur') 0\n",
      "\n",
      "Probabilities for test data:\n",
      "('sastra', 'university') 0.3333333333333333\n",
      "('university', 'thanjavur') 0\n",
      "('thanjavur', 'placement') 0\n",
      "('placement', 'good') 0\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams, FreqDist, word_tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "with open(\"main.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "text = preprocess_text(text)\n",
    "words = word_tokenize(text)\n",
    "split_index = len(words) // 2\n",
    "train_data = words[:split_index]\n",
    "held_out_data = words[split_index:]\n",
    "train_bigram = list(ngrams(train_data, 2))\n",
    "fidst_train = FreqDist(train_bigram)\n",
    "N_train = fidst_train.N()\n",
    "freq_of_freq_train = FreqDist(fidst_train.values())\n",
    "held_out_bigram = list(ngrams(held_out_data, 2))\n",
    "T = len(held_out_bigram)\n",
    "held_out_probabilities = {}\n",
    "for bigram in held_out_bigram:\n",
    "    r = fidst_train[bigram] if bigram in fidst_train else 0\n",
    "    Tr = freq_of_freq_train[r]\n",
    "    # Check if freq_of_freq_train[r] is zero to avoid division by zero\n",
    "    if freq_of_freq_train[r] != 0:\n",
    "        held_out_probabilities[bigram] = Tr / (T * freq_of_freq_train[r])\n",
    "    else:\n",
    "        held_out_probabilities[bigram] = 0\n",
    "print(\"Probabilities for held-out data:\")\n",
    "for bigram, prob in held_out_probabilities.items():\n",
    "    print(bigram, prob)\n",
    "with open(\"testdata.txt\", encoding=\"utf-8\") as f:\n",
    "    test_text = f.read()\n",
    "test_text = preprocess_text(test_text)\n",
    "test_data = word_tokenize(test_text)\n",
    "test_bigram = list(ngrams(test_data, 2))\n",
    "test_probabilities = {}\n",
    "for bigram in test_bigram:\n",
    "    if bigram in held_out_probabilities:\n",
    "        test_probabilities[bigram] = held_out_probabilities[bigram]\n",
    "    else:\n",
    "        test_probabilities[bigram] = 0\n",
    "\n",
    "print(\"\\nProbabilities for test data:\")\n",
    "for bigram, prob in test_probabilities.items():\n",
    "    print(bigram, prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa0ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
